{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "class TicTacToeQLearning:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.q_table = {}  # Q-value table\n",
        "\n",
        "    def get_state(self, board):\n",
        "        return tuple(board.flatten())\n",
        "\n",
        "    def get_available_actions(self, board):\n",
        "        return [i for i in range(9) if board.flatten()[i] == 0]\n",
        "\n",
        "    def choose_action(self, board, explore=True):\n",
        "        state = self.get_state(board)\n",
        "        available_actions = self.get_available_actions(board)\n",
        "\n",
        "        if explore and random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "\n",
        "        q_values = [self.q_table.get((state, a), 0) for a in available_actions]\n",
        "        max_q = max(q_values)\n",
        "        return random.choice([a for a, q in zip(available_actions, q_values) if q == max_q])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, done):\n",
        "        old_value = self.q_table.get((state, action), 0)\n",
        "        future_value = 0 if done else max([self.q_table.get((next_state, a), 0) for a in range(9)], default=0)\n",
        "        self.q_table[(state, action)] = old_value + self.alpha * (reward + self.gamma * future_value - old_value)\n",
        "\n",
        "    def train(self, episodes=10000):\n",
        "        for episode in range(episodes):\n",
        "            board = np.zeros((3, 3), dtype=int)\n",
        "            done = False\n",
        "            turn = 1  # 1 for player X, -1 for player O\n",
        "            states_actions = []\n",
        "\n",
        "            while not done:\n",
        "                action = self.choose_action(board)\n",
        "                state = self.get_state(board)\n",
        "                board.flat[action] = turn\n",
        "                self.visualize_board(board)\n",
        "                next_state = self.get_state(board)\n",
        "                states_actions.append((state, action))\n",
        "\n",
        "                if self.check_winner(board, turn):\n",
        "                    reward = 1 if turn == 1 else -1\n",
        "                    done = True\n",
        "                elif len(self.get_available_actions(board)) == 0:\n",
        "                    reward = 0  # Draw\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                self.update_q_table(state, action, reward, next_state, done)\n",
        "                turn *= -1\n",
        "                time.sleep(0.5)  # Add delay for better visualization\n",
        "\n",
        "    def visualize_board(self, board):\n",
        "        symbols = {1: 'X', -1: 'O', 0: '-'}\n",
        "        print(\"\\n\".join([\" \".join([symbols[cell] for cell in row]) for row in board]))\n",
        "        print(\"\\n\" + \"-\" * 10)\n",
        "\n",
        "    def check_winner(self, board, player):\n",
        "        for row in board:\n",
        "            if all(row == player):\n",
        "                return True\n",
        "        for col in board.T:\n",
        "            if all(col == player):\n",
        "                return True\n",
        "        if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def save_q_table(self, filename=\"q_table.pkl\"):\n",
        "      with open(filename, \"wb\") as f:\n",
        "        pickle.dump(self.q_table, f)\n",
        "        print(\"Q-Table:\")\n",
        "        for key, value in self.q_table.items():\n",
        "            print(f\"State: {key}, Action-Value: {value}\")\n",
        "\n",
        "\n",
        "\n",
        "    def load_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"rb\") as f:\n",
        "            self.q_table = pickle.load(f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agent = TicTacToeQLearning()\n",
        "    agent.train(2)\n",
        "    agent.save_q_table()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ulQ-POUyJNj",
        "outputId": "695dc84f-271f-4cc3-d37d-3c85dfce6dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- - -\n",
            "- - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - -\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- X -\n",
            "X - O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- X -\n",
            "X O O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- X X\n",
            "X O O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- X X\n",
            "X O O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "X X X\n",
            "X O O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- - -\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- - O\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- - O\n",
            "X X X\n",
            "\n",
            "----------\n",
            "Q-Table:\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), 7), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0)), 8), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(-1)), 3), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(-1)), 5), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(-1), np.int64(0), np.int64(1), np.int64(-1)), 1), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(0), np.int64(-1), np.int64(0), np.int64(1), np.int64(-1)), 4), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(1), np.int64(0), np.int64(1), np.int64(-1), np.int64(-1), np.int64(0), np.int64(1), np.int64(-1)), 2), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(-1), np.int64(-1), np.int64(0), np.int64(1), np.int64(-1)), 6), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(1), np.int64(1), np.int64(1), np.int64(-1), np.int64(-1), np.int64(-1), np.int64(1), np.int64(-1)), 0), Action-Value: 0.1\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0)), 6), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), 2), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(-1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(0)), 8), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(-1), np.int64(0), np.int64(0), np.int64(0), np.int64(1), np.int64(0), np.int64(1)), 5), Action-Value: 0.0\n",
            "State: ((np.int64(0), np.int64(0), np.int64(-1), np.int64(0), np.int64(0), np.int64(-1), np.int64(1), np.int64(0), np.int64(1)), 7), Action-Value: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "class TicTacToeQLearning:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.q_table = {}  # Q-value table\n",
        "\n",
        "    def get_state(self, board):\n",
        "        return tuple(board.flatten())\n",
        "\n",
        "    def get_available_actions(self, board):\n",
        "        return [i for i in range(9) if board.flatten()[i] == 0]\n",
        "\n",
        "    def choose_action(self, board, explore=True):\n",
        "        state = self.get_state(board)\n",
        "        available_actions = self.get_available_actions(board)\n",
        "\n",
        "        if explore and random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "\n",
        "        q_values = [self.q_table.get((state, a), 0) for a in available_actions]\n",
        "        max_q = max(q_values)\n",
        "        return random.choice([a for a, q in zip(available_actions, q_values) if q == max_q])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, done):\n",
        "        old_value = self.q_table.get((state, action), 0)\n",
        "        future_value = 0 if done else max([self.q_table.get((next_state, a), 0) for a in range(9)], default=0)\n",
        "        self.q_table[(state, action)] = old_value + self.alpha * (reward + self.gamma * future_value - old_value)\n",
        "\n",
        "    def train(self, episodes=10000):\n",
        "        for episode in range(episodes):\n",
        "            board = np.zeros((3, 3), dtype=int)\n",
        "            done = False\n",
        "            turn = 1  # 1 for player X, -1 for player O\n",
        "            states_actions = []\n",
        "\n",
        "            while not done:\n",
        "                action = self.choose_action(board)\n",
        "                state = self.get_state(board)\n",
        "                board.flat[action] = turn\n",
        "                self.visualize_board(board)\n",
        "                next_state = self.get_state(board)\n",
        "                states_actions.append((state, action))\n",
        "\n",
        "                if self.check_winner(board, turn):\n",
        "                    reward = 1 if turn == 1 else -1\n",
        "                    done = True\n",
        "                elif len(self.get_available_actions(board)) == 0:\n",
        "                    reward = 0  # Draw\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                self.update_q_table(state, action, reward, next_state, done)\n",
        "                turn *= -1\n",
        "                time.sleep(0.5)  # Add delay for better visualization\n",
        "\n",
        "    def visualize_board(self, board):\n",
        "        symbols = {1: 'X', -1: 'O', 0: '-'}\n",
        "        print(\"\\n\".join([\" \".join([symbols[cell] for cell in row]) for row in board]))\n",
        "        print(\"\\n\" + \"-\" * 10)\n",
        "\n",
        "    def check_winner(self, board, player):\n",
        "        for row in board:\n",
        "            if all(row == player):\n",
        "                return True\n",
        "        for col in board.T:\n",
        "            if all(col == player):\n",
        "                return True\n",
        "        if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def play_human_vs_ai(self):\n",
        "        board = np.zeros((3, 3), dtype=int)\n",
        "        self.load_q_table()\n",
        "        turn = 1  # Human starts as 'X'\n",
        "\n",
        "        while True:\n",
        "            self.visualize_board(board)\n",
        "\n",
        "            if turn == 1:\n",
        "                action = int(input(\"Enter your move (0-8): \"))\n",
        "            else:\n",
        "                action = self.choose_action(board, explore=False)\n",
        "                print(f\"AI chooses position: {action}\")\n",
        "\n",
        "            if action not in self.get_available_actions(board):\n",
        "                print(\"Invalid move! Try again.\")\n",
        "                continue\n",
        "\n",
        "            board.flat[action] = turn\n",
        "\n",
        "            if self.check_winner(board, turn):\n",
        "                self.visualize_board(board)\n",
        "                print(\"Player X wins!\" if turn == 1 else \"AI wins!\")\n",
        "                break\n",
        "            elif len(self.get_available_actions(board)) == 0:\n",
        "                self.visualize_board(board)\n",
        "                print(\"It's a draw!\")\n",
        "                break\n",
        "\n",
        "            turn *= -1\n",
        "\n",
        "    def save_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"wb\") as f:\n",
        "            pickle.dump(self.q_table, f)\n",
        "\n",
        "    def load_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"rb\") as f:\n",
        "            self.q_table = pickle.load(f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agent = TicTacToeQLearning()\n",
        "    agent.train(10)\n",
        "    agent.save_q_table()\n",
        "\n",
        "    print(\"Starting human vs AI mode!\")\n",
        "    agent.play_human_vs_ai()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQlM50E-0JH0",
        "outputId": "f652fef7-f0e5-4c24-e89a-01f13ee19d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- - -\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - X\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - X\n",
            "- - O\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - X\n",
            "X O O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X - X\n",
            "X O O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X O X\n",
            "X O O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "- - X\n",
            "X - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X O\n",
            "- - O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X X O\n",
            "X X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - O\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X X O\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X X O\n",
            "O - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X X O\n",
            "O X -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X X O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "- - X\n",
            "X X O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "O X X\n",
            "X X O\n",
            "O X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "O - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "O X -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- O -\n",
            "O X -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- O -\n",
            "O X -\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- O O\n",
            "O X -\n",
            "X - X\n",
            "\n",
            "----------\n",
            "X O O\n",
            "O X -\n",
            "X - X\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X X -\n",
            "- - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X X -\n",
            "- O -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X X -\n",
            "- O -\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X X -\n",
            "- O O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X X -\n",
            "- O O\n",
            "X X O\n",
            "\n",
            "----------\n",
            "X X O\n",
            "- O O\n",
            "X X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "- - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "O - O\n",
            "X - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "O - O\n",
            "X - -\n",
            "- X X\n",
            "\n",
            "----------\n",
            "O - O\n",
            "X - -\n",
            "O X X\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X - -\n",
            "O X X\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X - O\n",
            "O X X\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X X O\n",
            "O X X\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - X\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - X\n",
            "O - -\n",
            "\n",
            "----------\n",
            "- X O\n",
            "X - X\n",
            "O - -\n",
            "\n",
            "----------\n",
            "- X O\n",
            "X O X\n",
            "O - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- X -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X - O\n",
            "- X -\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X - O\n",
            "- X -\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X - O\n",
            "- X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - O\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - O\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X - O\n",
            "X O -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "X X O\n",
            "X O -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X X O\n",
            "X O -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "X X O\n",
            "X O X\n",
            "\n",
            "----------\n",
            "O - O\n",
            "X X O\n",
            "X O X\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X X O\n",
            "X O X\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "O - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- - -\n",
            "O X -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "O - -\n",
            "O X -\n",
            "\n",
            "----------\n",
            "X - X\n",
            "O - -\n",
            "O X -\n",
            "\n",
            "----------\n",
            "X - X\n",
            "O O -\n",
            "O X -\n",
            "\n",
            "----------\n",
            "X - X\n",
            "O O X\n",
            "O X -\n",
            "\n",
            "----------\n",
            "X - X\n",
            "O O X\n",
            "O X O\n",
            "\n",
            "----------\n",
            "X X X\n",
            "O O X\n",
            "O X O\n",
            "\n",
            "----------\n",
            "Starting human vs AI mode!\n",
            "- - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 1\n",
            "- X -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "AI chooses position: 2\n",
            "- X O\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 9\n",
            "Invalid move! Try again.\n",
            "- X O\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 6\n",
            "- X O\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "AI chooses position: 8\n",
            "- X O\n",
            "- - -\n",
            "X - O\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 5\n",
            "- X O\n",
            "- - X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "AI chooses position: 3\n",
            "- X O\n",
            "O - X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 4\n",
            "- X O\n",
            "O X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "AI chooses position: 0\n",
            "O X O\n",
            "O X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 7\n",
            "O X O\n",
            "O X X\n",
            "X X O\n",
            "\n",
            "----------\n",
            "Player X wins!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "class TicTacToeQLearning:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.q_table = {}  # Q-value table\n",
        "\n",
        "    def get_state(self, board):\n",
        "        return tuple(board.flatten())\n",
        "\n",
        "    def get_available_actions(self, board):\n",
        "        return [i for i in range(9) if board.flatten()[i] == 0]\n",
        "\n",
        "    def choose_action(self, board, explore=True):\n",
        "        state = self.get_state(board)\n",
        "        available_actions = self.get_available_actions(board)\n",
        "\n",
        "        if explore and random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "\n",
        "        q_values = [self.q_table.get((state, a), 0) for a in available_actions]\n",
        "        max_q = max(q_values)\n",
        "        return random.choice([a for a, q in zip(available_actions, q_values) if q == max_q])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state, done):\n",
        "        old_value = self.q_table.get((state, action), 0)\n",
        "        future_value = 0 if done else max([self.q_table.get((next_state, a), 0) for a in range(9)], default=0)\n",
        "        self.q_table[(state, action)] = old_value + self.alpha * (reward + self.gamma * future_value - old_value)\n",
        "\n",
        "    def train(self, episodes=10000):\n",
        "        for episode in range(episodes):\n",
        "            board = np.zeros((3, 3), dtype=int)\n",
        "            done = False\n",
        "            turn = 1  # 1 for player X, -1 for player O\n",
        "            states_actions = []\n",
        "\n",
        "            while not done:\n",
        "                action = self.choose_action(board)\n",
        "                state = self.get_state(board)\n",
        "                board.flat[action] = turn\n",
        "                self.visualize_board(board)\n",
        "                next_state = self.get_state(board)\n",
        "                states_actions.append((state, action))\n",
        "\n",
        "                if self.check_winner(board, turn):\n",
        "                    reward = 1 if turn == 1 else -1\n",
        "                    done = True\n",
        "                elif len(self.get_available_actions(board)) == 0:\n",
        "                    reward = 0  # Draw\n",
        "                    done = True\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                self.update_q_table(state, action, reward, next_state, done)\n",
        "                turn *= -1\n",
        "                time.sleep(0.5)  # Add delay for better visualization\n",
        "\n",
        "    def visualize_board(self, board):\n",
        "        symbols = {1: 'X', -1: 'O', 0: '-'}\n",
        "        print(\"\\n\".join([\" \".join([symbols[cell] for cell in row]) for row in board]))\n",
        "        print(\"\\n\" + \"-\" * 10)\n",
        "\n",
        "    def check_winner(self, board, player):\n",
        "        for row in board:\n",
        "            if all(row == player):\n",
        "                return True\n",
        "        for col in board.T:\n",
        "            if all(col == player):\n",
        "                return True\n",
        "        if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def play_human_vs_ai(self):\n",
        "        board = np.zeros((3, 3), dtype=int)\n",
        "        self.load_q_table()  # Load the saved Q-table\n",
        "        turn = 1  # Human starts as 'X'\n",
        "\n",
        "        while True:\n",
        "            self.visualize_board(board)\n",
        "\n",
        "            if turn == 1:\n",
        "                action = int(input(\"Enter your move (0-8): \"))\n",
        "            else:\n",
        "                action = self.choose_action(board, explore=False)  # AI's turn\n",
        "                print(f\"AI chooses position: {action}\")\n",
        "\n",
        "            if action not in self.get_available_actions(board):\n",
        "                print(\"Invalid move! Try again.\")\n",
        "                continue\n",
        "\n",
        "            board.flat[action] = turn\n",
        "            state = self.get_state(board)\n",
        "\n",
        "            if self.check_winner(board, turn):\n",
        "                self.visualize_board(board)\n",
        "                print(\"Player X wins!\" if turn == 1 else \"AI wins!\")\n",
        "\n",
        "                # Update Q-table based on the game result\n",
        "                if turn == -1: #AI won\n",
        "                  reward = 1\n",
        "                elif turn == 1: #Human won\n",
        "                  reward = -1\n",
        "                else: #draw\n",
        "                  reward = 0\n",
        "\n",
        "                self.update_q_table(state, action, reward, state, True) #update state-action pair for AI's winning/losing move\n",
        "\n",
        "                break\n",
        "            elif len(self.get_available_actions(board)) == 0:\n",
        "                self.visualize_board(board)\n",
        "                print(\"It's a draw!\")\n",
        "                break\n",
        "\n",
        "            turn *= -1\n",
        "\n",
        "    def save_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"wb\") as f:\n",
        "            pickle.dump(self.q_table, f)\n",
        "\n",
        "    def load_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"rb\") as f:\n",
        "            self.q_table = pickle.load(f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agent = TicTacToeQLearning()\n",
        "    agent.train(10)\n",
        "    agent.save_q_table()\n",
        "\n",
        "    while (True):\n",
        "        print(\"Starting human vs AI mode!\")\n",
        "        agent.play_human_vs_ai()\n",
        "        choice = input(\"Do you want to play again? (y/n): \")\n",
        "        if choice.lower() != 'y':\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAYw3cUOv1Bw",
        "outputId": "c7247b58-c0f2-4de2-dd81-cc595775b974"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- - -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- O -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- O -\n",
            "- - -\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- O -\n",
            "- - O\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- O -\n",
            "- X O\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- O O\n",
            "- X O\n",
            "X - X\n",
            "\n",
            "----------\n",
            "- O O\n",
            "- X O\n",
            "X X X\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- X O\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- X O\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- X O\n",
            "- - O\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X O -\n",
            "- X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X O X\n",
            "- X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X O X\n",
            "O X O\n",
            "- X O\n",
            "\n",
            "----------\n",
            "X O X\n",
            "O X O\n",
            "X X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "- - X\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- O -\n",
            "- - X\n",
            "\n",
            "----------\n",
            "X - -\n",
            "- O -\n",
            "- - X\n",
            "\n",
            "----------\n",
            "X O -\n",
            "- O -\n",
            "- - X\n",
            "\n",
            "----------\n",
            "X O X\n",
            "- O -\n",
            "- - X\n",
            "\n",
            "----------\n",
            "X O X\n",
            "- O -\n",
            "O - X\n",
            "\n",
            "----------\n",
            "X O X\n",
            "X O -\n",
            "O - X\n",
            "\n",
            "----------\n",
            "X O X\n",
            "X O O\n",
            "O - X\n",
            "\n",
            "----------\n",
            "X O X\n",
            "X O O\n",
            "O X X\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - X\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - X\n",
            "- - O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- X X\n",
            "- - O\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- X X\n",
            "- - O\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "- - O\n",
            "O X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "X - O\n",
            "O X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "X O O\n",
            "O X X\n",
            "X - O\n",
            "\n",
            "----------\n",
            "X O O\n",
            "O X X\n",
            "X X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "- - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - O\n",
            "X - -\n",
            "\n",
            "----------\n",
            "- - O\n",
            "X - O\n",
            "X X -\n",
            "\n",
            "----------\n",
            "O - O\n",
            "X - O\n",
            "X X -\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X - O\n",
            "X X -\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X O O\n",
            "X X -\n",
            "\n",
            "----------\n",
            "O X O\n",
            "X O O\n",
            "X X X\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- O -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X O -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "X O -\n",
            "- X -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "X O -\n",
            "- X -\n",
            "- O X\n",
            "\n",
            "----------\n",
            "- - X\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- - X\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- - X\n",
            "O - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- X X\n",
            "O - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- X X\n",
            "O - O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- X X\n",
            "O X O\n",
            "\n",
            "----------\n",
            "O - X\n",
            "O X X\n",
            "O X O\n",
            "\n",
            "----------\n",
            "- - X\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - X\n",
            "- - -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "- - X\n",
            "- - -\n",
            "X O -\n",
            "\n",
            "----------\n",
            "- O X\n",
            "- - -\n",
            "X O -\n",
            "\n",
            "----------\n",
            "- O X\n",
            "- - -\n",
            "X O X\n",
            "\n",
            "----------\n",
            "O O X\n",
            "- - -\n",
            "X O X\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X - -\n",
            "X O X\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X O -\n",
            "X O X\n",
            "\n",
            "----------\n",
            "- - X\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - X\n",
            "O - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "- - X\n",
            "O - -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "- - X\n",
            "O O -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "- X X\n",
            "O O -\n",
            "- X -\n",
            "\n",
            "----------\n",
            "- X X\n",
            "O O -\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- X X\n",
            "O O X\n",
            "- X O\n",
            "\n",
            "----------\n",
            "O X X\n",
            "O O X\n",
            "- X O\n",
            "\n",
            "----------\n",
            "- - -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "- X -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X O\n",
            "- O -\n",
            "\n",
            "----------\n",
            "O - X\n",
            "X X O\n",
            "- O X\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X X O\n",
            "- O X\n",
            "\n",
            "----------\n",
            "O O X\n",
            "X X O\n",
            "X O X\n",
            "\n",
            "----------\n",
            "Starting human vs AI mode!\n",
            "- - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 1\n",
            "- X -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "AI chooses position: 4\n",
            "- X -\n",
            "- O -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 2\n",
            "- X X\n",
            "- O -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "AI chooses position: 7\n",
            "- X X\n",
            "- O -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "Enter your move (0-8): 0\n",
            "X X X\n",
            "- O -\n",
            "- O -\n",
            "\n",
            "----------\n",
            "Player X wins!\n",
            "Do you want to play again? (y/n): n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Eligibility Traces"
      ],
      "metadata": {
        "id": "0PIhamJ43FJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "class TicTacToeQLearning:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.2, lambda_=0.8):\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.lambda_ = lambda_  # Trace decay factor\n",
        "\n",
        "        self.q_table = {}  # Q-value table\n",
        "        self.e_table = {}  # Eligibility trace table\n",
        "\n",
        "    def get_state(self, board):\n",
        "        return tuple(board.flatten())\n",
        "\n",
        "    def get_available_actions(self, board):\n",
        "        return [i for i in range(9) if board.flatten()[i] == 0]\n",
        "\n",
        "    def choose_action(self, board, explore=True):\n",
        "        state = self.get_state(board)\n",
        "        available_actions = self.get_available_actions(board)\n",
        "\n",
        "        if explore and random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_actions)  # Explore\n",
        "\n",
        "        q_values = [self.q_table.get((state, a), 0) for a in available_actions]\n",
        "        max_q = max(q_values, default=0)\n",
        "        return random.choice([a for a, q in zip(available_actions, q_values) if q == max_q])\n",
        "\n",
        "    def update_q_table(self, reward, next_state, done):\n",
        "        \"\"\"Update Q-values using TD(λ) with eligibility traces.\"\"\"\n",
        "        next_q = 0 if done else max([self.q_table.get((next_state, a), 0) for a in self.get_available_actions(np.array(next_state))], default=0)\n",
        "\n",
        "        for (state, action) in self.e_table.keys():\n",
        "            old_value = self.q_table.get((state, action), 0)\n",
        "            td_error = reward + self.gamma * next_q - old_value  # TD(0) error\n",
        "\n",
        "            # Update Q-value with eligibility trace\n",
        "            self.q_table[(state, action)] = old_value + self.alpha * td_error * self.e_table[(state, action)]\n",
        "\n",
        "            # Decay eligibility trace\n",
        "            self.e_table[(state, action)] *= self.gamma * self.lambda_\n",
        "\n",
        "    def train_ai_vs_ai(self, episodes=10000):\n",
        "        \"\"\"Train AI by playing AI vs AI for multiple episodes.\"\"\"\n",
        "        for episode in range(1, episodes + 1):\n",
        "            board = np.zeros((3, 3), dtype=int)\n",
        "            turn = 1  # AI-1 (X) starts\n",
        "            self.e_table.clear()  # Reset eligibility traces\n",
        "            states_actions = []\n",
        "\n",
        "            while True:\n",
        "                state = self.get_state(board)\n",
        "                action = self.choose_action(board, explore=True)\n",
        "                board.flat[action] = turn\n",
        "                next_state = self.get_state(board)\n",
        "\n",
        "                # Track state-action pairs for eligibility traces\n",
        "                states_actions.append((state, action))\n",
        "                self.e_table[(state, action)] = self.e_table.get((state, action), 0) + 1\n",
        "\n",
        "                if self.check_winner(board, turn):\n",
        "                    reward = 1 if turn == 1 else -1\n",
        "                    self.update_q_table(reward, next_state, done=True)\n",
        "                    break\n",
        "                elif len(self.get_available_actions(board)) == 0:\n",
        "                    self.update_q_table(0, next_state, done=True)\n",
        "                    break\n",
        "\n",
        "                self.update_q_table(0, next_state, done=False)\n",
        "                turn *= -1  # Switch turns\n",
        "\n",
        "            if episode % 1000 == 0:\n",
        "                print(f\"Training Episode {episode}/{episodes} completed.\")\n",
        "\n",
        "    def visualize_board(self, board):\n",
        "        symbols = {1: 'X', -1: 'O', 0: '-'}\n",
        "        print(\"\\n\".join([\" \".join([symbols[cell] for cell in row]) for row in board]))\n",
        "        print(\"\\n\" + \"-\" * 10)\n",
        "\n",
        "    def check_winner(self, board, player):\n",
        "        for row in board:\n",
        "            if all(row == player):\n",
        "                return True\n",
        "        for col in board.T:\n",
        "            if all(col == player):\n",
        "                return True\n",
        "        if all([board[i, i] == player for i in range(3)]) or all([board[i, 2 - i] == player for i in range(3)]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def save_q_table(self, filename=\"q_table.pkl\"):\n",
        "        with open(filename, \"wb\") as f:\n",
        "            pickle.dump(self.q_table, f)\n",
        "\n",
        "    def load_q_table(self, filename=\"q_table.pkl\"):\n",
        "        try:\n",
        "            with open(filename, \"rb\") as f:\n",
        "                self.q_table = pickle.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(\"No Q-table found, starting fresh.\")\n",
        "\n",
        "    def play_human_vs_ai(self):\n",
        "        \"\"\"Allows a human to play against the trained AI.\"\"\"\n",
        "        board = np.zeros((3, 3), dtype=int)\n",
        "\n",
        "        print(\"Welcome to Tic-Tac-Toe!\")\n",
        "        player_symbol = int(input(\"Choose your symbol: 1 for X, -1 for O: \"))\n",
        "        ai_symbol = -player_symbol\n",
        "\n",
        "        turn = 1  # X always starts\n",
        "        while True:\n",
        "            self.visualize_board(board)\n",
        "\n",
        "            if turn == player_symbol:\n",
        "                # Human turn\n",
        "                available_moves = self.get_available_actions(board)\n",
        "                move = -1\n",
        "                while move not in available_moves:\n",
        "                    try:\n",
        "                        move = int(input(f\"Your turn! Choose a position (0-8): \"))\n",
        "                        if move not in available_moves:\n",
        "                            print(\"Invalid move! Try again.\")\n",
        "                    except ValueError:\n",
        "                        print(\"Enter a valid integer between 0 and 8.\")\n",
        "                board.flat[move] = player_symbol\n",
        "            else:\n",
        "                # AI turn\n",
        "                print(\"AI is thinking...\")\n",
        "                move = self.choose_action(board, explore=False)\n",
        "                board.flat[move] = ai_symbol\n",
        "\n",
        "            # Check for win or draw\n",
        "            if self.check_winner(board, turn):\n",
        "                self.visualize_board(board)\n",
        "                if turn == player_symbol:\n",
        "                    print(\"Congratulations! You win!\")\n",
        "                else:\n",
        "                    print(\"AI wins! Better luck next time.\")\n",
        "                break\n",
        "            elif len(self.get_available_actions(board)) == 0:\n",
        "                self.visualize_board(board)\n",
        "                print(\"It's a draw!\")\n",
        "                break\n",
        "\n",
        "            turn *= -1  # Switch turns\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agent = TicTacToeQLearning()\n",
        "    agent.load_q_table()\n",
        "\n",
        "    print(\"Training AI vs AI...\")\n",
        "    agent.train_ai_vs_ai(episodes=10000)  # Train AI for 10,000 games\n",
        "    agent.save_q_table()\n",
        "\n",
        "    print(\"Training complete. Q-table saved!\")\n",
        "\n",
        "    # Play Human vs AI\n",
        "    agent.play_human_vs_ai()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXr60Dmw1RYG",
        "outputId": "75e3793a-464d-463c-94b9-080297f99ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AI vs AI...\n",
            "Training Episode 1000/10000 completed.\n",
            "Training Episode 2000/10000 completed.\n",
            "Training Episode 3000/10000 completed.\n",
            "Training Episode 4000/10000 completed.\n",
            "Training Episode 5000/10000 completed.\n",
            "Training Episode 6000/10000 completed.\n",
            "Training Episode 7000/10000 completed.\n",
            "Training Episode 8000/10000 completed.\n",
            "Training Episode 9000/10000 completed.\n",
            "Training Episode 10000/10000 completed.\n",
            "Training complete. Q-table saved!\n",
            "Welcome to Tic-Tac-Toe!\n",
            "Choose your symbol: 1 for X, -1 for O: -1\n",
            "- - -\n",
            "- - -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "AI is thinking...\n",
            "- - -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "Your turn! Choose a position (0-8): 1\n",
            "- O -\n",
            "- X -\n",
            "- - -\n",
            "\n",
            "----------\n",
            "AI is thinking...\n",
            "- O -\n",
            "- X -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "Your turn! Choose a position (0-8): 2\n",
            "- O O\n",
            "- X -\n",
            "X - -\n",
            "\n",
            "----------\n",
            "AI is thinking...\n",
            "- O O\n",
            "- X X\n",
            "X - -\n",
            "\n",
            "----------\n",
            "Your turn! Choose a position (0-8): 3\n",
            "- O O\n",
            "O X X\n",
            "X - -\n",
            "\n",
            "----------\n",
            "AI is thinking...\n",
            "- O O\n",
            "O X X\n",
            "X - X\n",
            "\n",
            "----------\n",
            "Your turn! Choose a position (0-8): 0\n",
            "O O O\n",
            "O X X\n",
            "X - X\n",
            "\n",
            "----------\n",
            "Congratulations! You win!\n"
          ]
        }
      ]
    }
  ]
}
